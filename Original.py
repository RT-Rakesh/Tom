# -*- coding: utf-8 -*-
"""Untitled35.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1paXgyepFnyJ-IC_PrGTT3rTf7cNe52V_
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPRegressor




df=pd.read_csv('./Toronto_apartment_rentals_2018.csv')



def parse_address(address):
    street_number_pattern = r'^(\d+)'
    street_name_pattern = r'^\d+\s+(.+?),'
    city_province_pattern = r',\s*([A-Za-z\s]+),\s*([A-Za-z]{2})'
    postal_code_pattern = r'([A-Za-z]\d[A-Za-z] \d[A-Za-z]\d)'
    country_pattern = r'Canada$'

    # Extract street number, street name, city, province, postal code, and country
    street_number = re.search(street_number_pattern, address)
    street_name = re.search(street_name_pattern, address)
    city_province = re.search(city_province_pattern, address)
    postal_code = re.search(postal_code_pattern, address)
    country = re.search(country_pattern, address)

    # Assign the values to the respective components
    street_number = street_number.group(1).strip() if street_number else ''
    street_name = street_name.group(1).strip() if street_name else ''
    city = city_province.group(1).strip() if city_province else ''
    province = city_province.group(2).strip() if city_province else ''
    postal_code = postal_code.group(1).strip() if postal_code else ''
    country = 'Canada' if country else ''

    return street_number, street_name, city, province, postal_code, country

# Apply the parsing function to the 'Address' column
df['Street Number'], df['Street'], df['City'], df['Province'], df['Postal Code'], df['Country'] = zip(*df['Address'].apply(parse_address))

# Display the DataFrame with parsed components
print(df)

df['Price'] = df['Price'].str.replace('$', '')
df['Price'] = df['Price'].str.replace(',', '').astype(float)

df=df.drop(columns=['Address','Street Number', 'Street', 'City', 'Province','Country'])

# Example to check for empty spaces
for column in df.columns:
    if df[column].dtype == 'object':  # Only apply to columns with object (string) dtype
        empty_spaces_count = (df[column].str.strip() == '').sum()
        if empty_spaces_count > 0:
            print(f"Column '{column}' has {empty_spaces_count} empty spaces.")

for column in df.columns:
    if df[column].dtype == 'object':  # Only apply to columns with object (string) dtype
        df[column] = df[column].replace(r'^\s*$', np.nan, regex=True)


missing_values_per_row = df.isnull().sum(axis=1)

num_rows_with_more_than_one_missing = (missing_values_per_row > 1).sum()

print("Number of rows with more than one missing value:", num_rows_with_more_than_one_missing)

df = df.dropna()

postal_codes =df['Postal Code'].tolist()

def categorize_postal_codes(postal_codes):
    neighborhood_mapping = {}
    neighborhood_counter = 1

    categorized_neighborhoods = []

    for postal_code in postal_codes:
        prefix = postal_code[:3]

        if prefix not in neighborhood_mapping:
            neighborhood_mapping[prefix] = f"Neighborhood {neighborhood_counter}"
            neighborhood_counter += 1

        categorized_neighborhoods.append(neighborhood_mapping[prefix])

    return categorized_neighborhoods

neighborhoods = categorize_postal_codes(postal_codes)

df['Neighborhood'] = neighborhoods

unique_neighborhoods = df['Neighborhood'].unique()

df = df[df['Price'] <= 10000]

categorical_features = ["Neighborhood"]

encoder = OneHotEncoder(handle_unknown="ignore", sparse_output=False)
matrix = encoder.fit_transform(df[categorical_features])
encoder_feature_names = encoder.get_feature_names_out()
df_encoded = pd.DataFrame(data=matrix, columns=encoder_feature_names)
df = pd.merge(df, df_encoded, left_index=True, right_index=True)
df.drop(columns=categorical_features, inplace=True)
df.head()

features_to_scale = ['Bedroom', 'Bathroom', 'Den', 'Lat', 'Long', 'Price']
scaler = StandardScaler()
df[features_to_scale] = scaler.fit_transform(df[features_to_scale])

X = df.drop(columns=["Price", "Postal Code"])
y = df["Price"]

X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.20,
                                                    random_state=42)

print(f"Train Shape: {X_train.shape}")
print(f"Test Shape: {X_test.shape}")

model = MLPRegressor(
    random_state=42,
    max_iter=2000,
    hidden_layer_sizes=(100, 80, 50),
    n_iter_no_change=500,
    early_stopping=True,
    verbose=True,
    validation_fraction= 0.1
)

model.fit(X_train, y_train)

model.score(X_test, y_test)
model.score(X_train, y_train)